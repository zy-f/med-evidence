LLM_MODEL_MAP = { # shorthand name -> (provider, full model id/name under the provider)
    "gpt4_1": ('openai', 'gpt-4.1'),
    "gpt4_1mini": ('openai', 'gpt-4.1-mini'),
    "gpt4o": ('openai', 'gpt-4o'),
    "gpto1": ('openai', 'o1'),
    "openthinker2_32b": ('vllm', 'open-thoughts/OpenThinker2-32B'),
    "llama70b_r1distill": ('together', 'deepseek-ai/DeepSeek-R1-Distill-Llama-70B'),
    "llama70b_instruct": ('together', 'meta-llama/Llama-3.3-70B-Instruct-Turbo'),
    "llama3_1_405b": ('together', 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo'),
    "llama3_1_70b": ('together', 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo'),
    "llama3_1_8b": ('together', 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo'),
    "llama4scout": ('together', 'meta-llama/Llama-4-Scout-17B-16E-Instruct'),
    "llama4mav": ('together', 'meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8'),
    "llama3_8b": ('together', 'meta-llama/Llama-3-8b-chat-hf'),
    "llama3_70b": ('together', 'meta-llama/Llama-3-70b-chat-hf'),
    "qwen3_235b": ('together', 'Qwen/Qwen3-235B-A22B-fp8-tput'),
    "qwen72b": ('together', 'Qwen/Qwen2.5-72B-Instruct-Turbo'),
    # "qwen7b": ('vllm', 'Qwen/Qwen2.5-7B-Instruct'),
    "qwen7b": ('together', 'Qwen/Qwen2.5-7B-Instruct-Turbo'),
    "qwen32b": ('vllm', 'Qwen/Qwen2.5-32B-Instruct'),
    "qwq32b": ('together', 'Qwen/QwQ-32B'),
    "deepseekR1": ('together', 'deepseek-ai/DeepSeek-R1'),
    "deepseekV3": ('together', 'deepseek-ai/DeepSeek-V3'),
    "mixtral8x7b": ('vllm', 'mistralai/Mixtral-8x7B-v0.1'),
    "huatuo7b": ('vllm', 'FreedomIntelligence/HuatuoGPT-o1-7B'),
    "huatuo70b": ('vllm', 'FreedomIntelligence/HuatuoGPT-o1-70B'),
    "openbiollm_8b": ('vllm', 'aaditya/Llama3-OpenBioLLM-8B'),
    "openbiollm_70b": ('vllm', 'aaditya/Llama3-OpenBioLLM-70B'),
    # "mmed_llama3_8b": ('vllm', 'Henrychur/MMed-Llama-3-8B-EnIns')
}

KNOWN_MAX_TOKENS = {
    "gpt-4o": 128_000,
    "gpt-4.1": 1_000_000,
    "o1": 150_000,
    "gpt-4.1-mini": 128_000,
    "Qwen/Qwen2.5-7B-Instruct": 28_000,
    "Qwen/Qwen2.5-32B-Instruct": 28_000,
    "Qwen/Qwen3-235B-A22B-fp8-tput": 28_000,
    "Qwen/QwQ-32B": 128_000,
    "Qwen/Qwen2.5-72B-Instruct-Turbo": 28_000,
    "mistralai/Mixtral-8x7B-v0.1": 28_000,
    "deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free": 4_096,
    "deepseek-ai/DeepSeek-R1-Distill-Llama-70B": 128_000,
    "deepseek-ai/DeepSeek-R1": 128_000,
    "deepseek-ai/DeepSeek-V3": 128_000,
    "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free": 7_000,
    "meta-llama/Llama-3.3-70B-Instruct-Turbo": 128_000,
    "meta-llama/Llama-4-Scout-17B-16E-Instruct": 1_000_000,
    "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": 500_000,
    "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": 128_000,
    "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": 128_000,
    "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": 128_000,
    "meta-llama/Llama-3-8b-chat-hf": 4_096,
    "meta-llama/Llama-3-70b-chat-hf": 4_096,
    "FreedomIntelligence/HuatuoGPT-o1-7B": 28_000,
    "aaditya/Llama3-OpenBioLLM-8B": 4_096,
    "Henrychur/MMed-Llama-3-8B-EnIns": 4_096,
    "aaditya/Llama3-OpenBioLLM-70B": 4_096,
    "FreedomIntelligence/HuatuoGPT-o1-70B": 8_000,
    "open-thoughts/OpenThinker2-32B": 28_000,
}

ANSWER_CLASSES = ["Higher", "Lower", "No Difference", "Insufficient Data", "Uncertain Effect"]
